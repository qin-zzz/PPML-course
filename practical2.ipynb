{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Privacy Preserving Machine Learning\n",
    "\n",
    "Course taught by Aurélien Bellet\n",
    "\n",
    "Course page: http://researchers.lille.inria.fr/abellet/teaching/private_machine_learning_course.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical session 2: Differential privacy for non-numeric queries & using composition results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be working again with the US Census dataset. You can read about the dataset [here](https://archive.ics.uci.edu/ml/datasets/census+income).\n",
    "\n",
    "The following line loads the dataset from [OpenML](https://www.openml.org/) with the `fetch_openml` method of `sklearn`. The option `as_frame=True` loads the dataset in `pandas DataFrame` format: this keeps the attributes in their original form and will be more convenient to work with. If you prefer working with a numpy array (not recommended), set `as_frame=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_handle = fetch_openml(name='adult', version=2, as_frame=True)\n",
    "dataset = dataset_handle.frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48842 15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802.0</td>\n",
       "      <td>11th</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.0</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951.0</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323.0</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103497.0</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>34.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>198693.0</td>\n",
       "      <td>10th</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>227026.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>63.0</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>104626.0</td>\n",
       "      <td>Prof-school</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>3103.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>24.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>369667.0</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>55.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>104996.0</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age         workclass    fnlwgt     education  education-num  \\\n",
       "0  25.0           Private  226802.0          11th            7.0   \n",
       "1  38.0           Private   89814.0       HS-grad            9.0   \n",
       "2  28.0         Local-gov  336951.0    Assoc-acdm           12.0   \n",
       "3  44.0           Private  160323.0  Some-college           10.0   \n",
       "4  18.0               NaN  103497.0  Some-college           10.0   \n",
       "5  34.0           Private  198693.0          10th            6.0   \n",
       "6  29.0               NaN  227026.0       HS-grad            9.0   \n",
       "7  63.0  Self-emp-not-inc  104626.0   Prof-school           15.0   \n",
       "8  24.0           Private  369667.0  Some-college           10.0   \n",
       "9  55.0           Private  104996.0       7th-8th            4.0   \n",
       "\n",
       "       marital-status         occupation   relationship   race     sex  \\\n",
       "0       Never-married  Machine-op-inspct      Own-child  Black    Male   \n",
       "1  Married-civ-spouse    Farming-fishing        Husband  White    Male   \n",
       "2  Married-civ-spouse    Protective-serv        Husband  White    Male   \n",
       "3  Married-civ-spouse  Machine-op-inspct        Husband  Black    Male   \n",
       "4       Never-married                NaN      Own-child  White  Female   \n",
       "5       Never-married      Other-service  Not-in-family  White    Male   \n",
       "6       Never-married                NaN      Unmarried  Black    Male   \n",
       "7  Married-civ-spouse     Prof-specialty        Husband  White    Male   \n",
       "8       Never-married      Other-service      Unmarried  White  Female   \n",
       "9  Married-civ-spouse       Craft-repair        Husband  White    Male   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week native-country  class  \n",
       "0           0.0           0.0            40.0  United-States  <=50K  \n",
       "1           0.0           0.0            50.0  United-States  <=50K  \n",
       "2           0.0           0.0            40.0  United-States   >50K  \n",
       "3        7688.0           0.0            40.0  United-States   >50K  \n",
       "4           0.0           0.0            30.0  United-States  <=50K  \n",
       "5           0.0           0.0            30.0  United-States  <=50K  \n",
       "6           0.0           0.0            40.0  United-States  <=50K  \n",
       "7        3103.0           0.0            32.0  United-States   >50K  \n",
       "8           0.0           0.0            40.0  United-States  <=50K  \n",
       "9           0.0           0.0            10.0  United-States  <=50K  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n, d = dataset.shape\n",
    "print(n, d)\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 (\"most common\" query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a function for \"most common\" queries: it takes as input a dataset (`DataFrame`), an attribute (e.g., `\"education\"`), and returns the most common value of this attribute in the dataset (ties can be broken arbitrarily). Note that in general, the output of such queries is non-numeric. The pandas methods `value_counts`, `idxmax()` or `mode` can be useful here.\n",
    "\n",
    "Test your function on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common_query(df, attribute):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        Dataset\n",
    "    attribute : string\n",
    "        Name of an attribute (with categorical values)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    value : float or string\n",
    "        The most common value of `attribute` in dataset `df`\n",
    "    '''\n",
    "    \n",
    "    # TO COMPLETE\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 (Exponential mechanism)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the exponential mechanism, i.e., a function which takes as input the list of possible outputs, the corresponding scores (assuming a numpy array format will be most convenient), the sensitivity of the score function, the desired value of $\\epsilon$ and a random seed (for reproducibility), and returns an output selected in an $\\epsilon$-differentially private way. To sample an ouput, use `numpy.random.choice`.\n",
    "\n",
    "**Careful**: if you implement the exponential mechanism naively you will get numerical errors because un-normalized probabilities will quickly become very large. You should compute everything in log domain and only take the exponential at the end. To compute the normalization term in log domain, you can use `scipy.special.logsumexp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_mechanism(outputs, scores, sensitivity, eps, random_state=None):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    outputs : list\n",
    "        Possible outputs for the query\n",
    "    scores : array of float \n",
    "        Scores associated to each output\n",
    "    sensitivity : float\n",
    "        The sensitivity of the score\n",
    "    eps : float\n",
    "        Parameter epsilon of differential privacy\n",
    "    random_state : int, optional (default=None)\n",
    "        Random seed\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    private_q : float or string (sans as outputs)\n",
    "        An eps-DP evaluation of the query\n",
    "    '''\n",
    "    \n",
    "    rng = np.random.RandomState(random_state)\n",
    "    # TO COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 (Exponential mechanism on \"most common\" queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to use the exponential mechanism to privately answer the following queries:\n",
    "- What is the most common level of education of people in the dataset?\n",
    "- What is the most common occupation of people in the dataset?\n",
    "- What is the most common age of people in the dataset?\n",
    "\n",
    "Define an appropriate score function for these queries. What is the sensitivity of your score function?\n",
    "\n",
    "Use the exponential mechanism to privately answer these queries for $\\epsilon=0.1$ and several random executions. Compare the output to the non-private result, and explain why for some queries the true (non-private) output is returned more often."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def private_most_common_query(df, attribute, eps, random_state=None):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        Dataset\n",
    "    attribute : string\n",
    "        Name of an attribute (with categorical values)\n",
    "    eps : float\n",
    "        Parameter epsilon of differential privacy\n",
    "    random_state : int, optional (default=None)\n",
    "        Random seed\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    private_q : float or string\n",
    "        An eps-DP evaluation of the \"most common\" query on `attribute`\n",
    "    '''\n",
    "    \n",
    "    d = dict(df[attribute].value_counts())\n",
    "    outputs = list(d.keys())\n",
    "    # TO COMPLETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Attribute queries: education\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "\n",
      "Attribute queries: occupation\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "\n",
      "Attribute queries: age\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "query_attribute = ['education', 'occupation', 'age']\n",
    "\n",
    "for attr in query_attribute:\n",
    "    print(\"\\nAttribute queries:\", attr)\n",
    "    for r in range(20):\n",
    "        print(private_most_common_query(dataset, attr, 0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 (Exponential mechanism for model selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that you would like to build a model to predict the income of an individual based on its personal features (for instance, to study which features are predictive of income). You have access to a small *public* dataset of 50 people in the same format as the US Census dataset we have been working with so far, and you would like to train a classifier to predict whether an individual makes more than 50$/year from its personal features. However, there are hyper-parameters to tune and you know the dataset is too small to reliably estimate the generalization performance of each model to select the best.\n",
    "\n",
    "There exists a larger dataset held by the US Census on which you could perform model selection, but this dataset is *private*. Therefore you would like to privately perform model selection on this dataset, i.e., among the set of models you trained on the small public dataset, you would like to select the one which performs best on the private dataset in an $\\epsilon$-DP fashion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simulate this scenario, we use the same dataset as before. For convenience, we load it in numpy format where all categorical features have been coded as numerical variables, and remove the features that have missing values. We then split the full dataset into a small dataset with 50 people (the *public* dataset) and a larger dataset of 48K+ people (the *private* dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 11) (50,) (48792, 11) (48792,)\n"
     ]
    }
   ],
   "source": [
    "X, y = fetch_openml(name='adult', version=2, return_X_y=True, as_frame=False)\n",
    "features_complete = (np.isnan(X).sum(axis=0)) == 0 # features without missing values\n",
    "X = X[:, features_complete]\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X_public, X_private, y_public, y_private = train_test_split(X, y, train_size=50, random_state=42)\n",
    "print(X_public.shape, y_public.shape, X_private.shape, y_private.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What is the output space of the query?\n",
    "2. How to define the score function in this case? What is its sensitivity?\n",
    "3. Implement a function for private model selection with the exponential mechanism: it takes as input the public and the private datasets, a scikit-learn model (e.g., `LogisticRegression()`), a `ParameterGrid` (see [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ParameterGrid.html)) giving the possible hyper-parameters and values, the desired value of $\\epsilon$ and a random seed (for reproducibility), and returns a set of hyper-parameters selected in an $\\epsilon$-DP way.\n",
    "4. Run this to tune the value of the parameter `C` of `LogisticRegression()`. You may also try other cases, e.g., tuning the choice of kernel, parameter `C` and parameter `gamma` of the RBF kernel in a SVM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def private_model_selection(X_public, y_public, X_private, y_private, model, grid, eps, random_state=None):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_public : array of shape (n1, d)\n",
    "        Public dataset\n",
    "    y_public : array of shape (n1,)\n",
    "        Public labels\n",
    "    X_private : array of shape (n2, d)\n",
    "        Private dataset\n",
    "    y_private : array of shape (n2,)\n",
    "        Private labels\n",
    "    model : BaseEstimator\n",
    "        An instance of a scikit-learn model\n",
    "    grid : ParameterGrid\n",
    "        A grid describing the set of hyperparameters to tune and their possible values\n",
    "    eps : float\n",
    "        Parameter epsilon of differential privacy\n",
    "    random_state : int, optional (default=None)\n",
    "        Random seed\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    private_best_params : dict\n",
    "        An eps-DP evaluation of best hyperparameter search\n",
    "    '''\n",
    "\n",
    "    n_private = X_private.shape[0]\n",
    "    accuracies = np.zeros(len(grid))\n",
    "    for i, param in enumerate(grid):\n",
    "        model.set_params(**param)\n",
    "        # TO COMPLETE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'C':np.geomspace(1e-3, 1e3, num=100)}\n",
    "grid = ParameterGrid(params)\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "# TO COMPLETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [{'kernel':['rbf'], 'gamma':np.geomspace(1e-4, 1e4, num=20), 'C': np.geomspace(1e-3, 1e3, num=10)},\n",
    "              {'kernel':['linear'], 'C':np.geomspace(1e-3, 1e3, num=10)}]\n",
    "grid = ParameterGrid(params)\n",
    "model = SVC()\n",
    "# TO COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5 (using composition results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this question we will work with the MovieLens 1M dataset, which contains 1,000,000 ratings in {1, 2, 3, 4, 5} given by 6040 users on 3706 movies (there is of course a lot of missing values!). There exists even bigger versions of this dataset, see [here](https://grouplens.org/datasets/movielens/).\n",
    "\n",
    "The code below loads the MovieLens 1M dataset, formats it to have users as rows and drops movies with less than 1000 ratings. Before executing this, [download the dataset](http://files.grouplens.org/datasets/movielens/ml-1m.zip) and unzip the file in the same directory as your Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>2001: A Space Odyssey (1968)</th>\n",
       "      <th>Abyss, The (1989)</th>\n",
       "      <th>African Queen, The (1951)</th>\n",
       "      <th>Air Force One (1997)</th>\n",
       "      <th>Airplane! (1980)</th>\n",
       "      <th>...</th>\n",
       "      <th>Untouchables, The (1987)</th>\n",
       "      <th>Usual Suspects, The (1995)</th>\n",
       "      <th>Wayne's World (1992)</th>\n",
       "      <th>When Harry Met Sally... (1989)</th>\n",
       "      <th>Who Framed Roger Rabbit? (1988)</th>\n",
       "      <th>Willy Wonka and the Chocolate Factory (1971)</th>\n",
       "      <th>Witness (1985)</th>\n",
       "      <th>Wizard of Oz, The (1939)</th>\n",
       "      <th>X-Men (2000)</th>\n",
       "      <th>Young Frankenstein (1974)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>70072</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>55117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>02460</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>55455</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6035</th>\n",
       "      <td>6036</td>\n",
       "      <td>F</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>32603</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6036</th>\n",
       "      <td>6037</td>\n",
       "      <td>F</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>76006</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6037</th>\n",
       "      <td>6038</td>\n",
       "      <td>F</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>14706</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6038</th>\n",
       "      <td>6039</td>\n",
       "      <td>F</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>01060</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6039</th>\n",
       "      <td>6040</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>11106</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6040 rows × 212 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id age  sex  occupation zip_code  2001: A Space Odyssey (1968)  \\\n",
       "0           1   F    1          10    48067                           NaN   \n",
       "1           2   M   56          16    70072                           NaN   \n",
       "2           3   M   25          15    55117                           NaN   \n",
       "3           4   M   45           7    02460                           NaN   \n",
       "4           5   M   25          20    55455                           NaN   \n",
       "...       ...  ..  ...         ...      ...                           ...   \n",
       "6035     6036   F   25          15    32603                           5.0   \n",
       "6036     6037   F   45           1    76006                           5.0   \n",
       "6037     6038   F   56           1    14706                           NaN   \n",
       "6038     6039   F   45           0    01060                           4.0   \n",
       "6039     6040   M   25           6    11106                           5.0   \n",
       "\n",
       "      Abyss, The (1989)  African Queen, The (1951)  Air Force One (1997)  \\\n",
       "0                   NaN                        NaN                   NaN   \n",
       "1                   NaN                        NaN                   NaN   \n",
       "2                   NaN                        NaN                   NaN   \n",
       "3                   NaN                        NaN                   NaN   \n",
       "4                   1.0                        NaN                   NaN   \n",
       "...                 ...                        ...                   ...   \n",
       "6035                4.0                        4.0                   NaN   \n",
       "6036                4.0                        NaN                   NaN   \n",
       "6037                NaN                        NaN                   NaN   \n",
       "6038                NaN                        NaN                   NaN   \n",
       "6039                3.0                        NaN                   NaN   \n",
       "\n",
       "      Airplane! (1980)  ...  Untouchables, The (1987)  \\\n",
       "0                  4.0  ...                       NaN   \n",
       "1                  NaN  ...                       4.0   \n",
       "2                  NaN  ...                       NaN   \n",
       "3                  NaN  ...                       NaN   \n",
       "4                  NaN  ...                       NaN   \n",
       "...                ...  ...                       ...   \n",
       "6035               3.0  ...                       NaN   \n",
       "6036               NaN  ...                       NaN   \n",
       "6037               NaN  ...                       NaN   \n",
       "6038               4.0  ...                       NaN   \n",
       "6039               4.0  ...                       NaN   \n",
       "\n",
       "      Usual Suspects, The (1995)  Wayne's World (1992)  \\\n",
       "0                            NaN                   NaN   \n",
       "1                            NaN                   NaN   \n",
       "2                            NaN                   NaN   \n",
       "3                            NaN                   NaN   \n",
       "4                            5.0                   NaN   \n",
       "...                          ...                   ...   \n",
       "6035                         3.0                   NaN   \n",
       "6036                         4.0                   NaN   \n",
       "6037                         NaN                   NaN   \n",
       "6038                         NaN                   NaN   \n",
       "6039                         4.0                   NaN   \n",
       "\n",
       "      When Harry Met Sally... (1989)  Who Framed Roger Rabbit? (1988)  \\\n",
       "0                                NaN                              NaN   \n",
       "1                                NaN                              NaN   \n",
       "2                                NaN                              NaN   \n",
       "3                                NaN                              NaN   \n",
       "4                                NaN                              4.0   \n",
       "...                              ...                              ...   \n",
       "6035                             2.0                              2.0   \n",
       "6036                             4.0                              NaN   \n",
       "6037                             NaN                              NaN   \n",
       "6038                             NaN                              NaN   \n",
       "6039                             5.0                              1.0   \n",
       "\n",
       "      Willy Wonka and the Chocolate Factory (1971)  Witness (1985)  \\\n",
       "0                                              NaN             NaN   \n",
       "1                                              NaN             NaN   \n",
       "2                                              NaN             NaN   \n",
       "3                                              NaN             NaN   \n",
       "4                                              NaN             NaN   \n",
       "...                                            ...             ...   \n",
       "6035                                           NaN             4.0   \n",
       "6036                                           NaN             4.0   \n",
       "6037                                           NaN             NaN   \n",
       "6038                                           NaN             NaN   \n",
       "6039                                           NaN             4.0   \n",
       "\n",
       "      Wizard of Oz, The (1939)  X-Men (2000)  Young Frankenstein (1974)  \n",
       "0                          4.0           NaN                        NaN  \n",
       "1                          NaN           NaN                        NaN  \n",
       "2                          NaN           NaN                        NaN  \n",
       "3                          NaN           NaN                        NaN  \n",
       "4                          4.0           2.0                        NaN  \n",
       "...                        ...           ...                        ...  \n",
       "6035                       NaN           NaN                        4.0  \n",
       "6036                       4.0           NaN                        NaN  \n",
       "6037                       NaN           NaN                        NaN  \n",
       "6038                       4.0           NaN                        NaN  \n",
       "6039                       5.0           NaN                        4.0  \n",
       "\n",
       "[6040 rows x 212 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "users = pd.read_csv('ml-1m/users.dat', sep='::', names=u_cols, engine='python')\n",
    "\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "ratings = pd.read_csv('ml-1m/ratings.dat', sep='::', names=r_cols, engine='python')\n",
    "\n",
    "m_cols = ['movie_id', 'title', 'release_date']\n",
    "movies = pd.read_csv('ml-1m/movies.dat', sep='::', names=m_cols, engine='python', encoding_errors='ignore')\n",
    "\n",
    "movie_ratings = pd.merge(movies, ratings)\n",
    "user_ratings = pd.merge(users, movie_ratings[['user_id', 'title', 'rating']])\n",
    "user_ratings = (user_ratings.pivot_table(index=['user_id', 'age', 'sex', 'occupation', 'zip_code'],\n",
    "                                         columns='title', values='rating').reset_index())\n",
    "user_ratings.columns.name=\"\"\n",
    "user_ratings = user_ratings.dropna(thresh=1000, axis=1)\n",
    "movie_list = list(user_ratings.columns[5:])\n",
    "n_movies = len(movie_list)\n",
    "user_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would now like to privately compute the majority rating among users for each movie in the dataset. This is a lot of queries (207) and unfortunately each user can potentially affect all of them. Compare the use of simple and advanced composition to calibrate the noise for each query so as to satisfy a fixed $(\\epsilon,\\delta)$-DP guarantee for the entire process. Comment the results.\n",
    "\n",
    "**Note:** To simplify a bit the implementation, you can:\n",
    "- assume that all possible ratings (1, 2, 3, 4, 5) have non-zero count for each movie (this is likely to be the case since we are working on movies with at least 1,000 ratings). A better implementation would make sure that ratings not seen for a movie are assigned a count of 0 so that the exponential mechanism is truly safe (see lecture).\n",
    "- measure the error as the frequency of getting the same answer as the non-private query, that is, you can ignore ties (several ratings may have maximal count). Again, ties are unlikely to happen for movies with more than 1,000 ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_error(df, attribute_list, eps, random_state=None):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        Dataset\n",
    "    attribute_list : list of string\n",
    "        List of attribute names\n",
    "    eps : float\n",
    "        Parameter epsilon of differential privacy\n",
    "    random_state : int, optional (default=None)\n",
    "        Random seed\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    error : float\n",
    "        The frequency that the private query returns the same answer as the non-private query\n",
    "    '''\n",
    "    \n",
    "    error = 0\n",
    "    for a in attribute_list:\n",
    "        # TO COMPLETE\n",
    "        pass\n",
    "    error /= len(attribute_list)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Simple composition**\n",
      "Value of epsilon for each individual query 0\n",
      "Average error: 0.0\n",
      "\n",
      "**Advanced composition**\n",
      "Value of epsilon for each individual query 0\n",
      "Average error: 0.0\n"
     ]
    }
   ],
   "source": [
    "eps_final = 2.\n",
    "k = len(movie_list) # number of movies\n",
    "\n",
    "# TO COMPLETE\n",
    "eps0_simple = 0\n",
    "eps0_advanced = 0 \n",
    "\n",
    "n_runs = 5\n",
    "error_simple = 0\n",
    "error_advanced = 0\n",
    "for r in range(n_runs):\n",
    "    # TO COMPLETE\n",
    "    # error_simple += \n",
    "    # error_advanced += \n",
    "    pass\n",
    "error_simple /= n_runs\n",
    "error_advanced /= n_runs\n",
    "\n",
    "print(\"**Simple composition**\")\n",
    "print(\"Value of epsilon for each individual query\", eps0_simple)\n",
    "print(\"Average error:\", error_simple)\n",
    "\n",
    "print(\"\\n**Advanced composition**\")\n",
    "print(\"Value of epsilon for each individual query\", eps0_advanced)\n",
    "print(\"Average error:\", error_advanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Question 1 (Laplace mechanism and Report Noisy Max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Propose a simple way to privately answer the queries of Questions 3 and 4 using the Laplace mechanism instead of the exponential mechanism. What is the $\\ell_1$ sensitivity for the two cases? For Question 4, do you think it is possible to do better with the Laplace mechanism?\n",
    "2. Read about Report Noisy Max in Section 3.3 of [Dwork & Roth (2014)](https://www.cis.upenn.edu/~aaroth/Papers/privacybook.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Question 2 (Even better composition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Question 5 above, when using advanced composition, we have picked the $\\epsilon_0$ to use for each individual query using the convenient cororally seen in the lecture. However this corollary is not tight and it is better to use the advanced composition theorem directly. Implement a function to choose the smallest admissible value $\\epsilon_0$ according to the theorem and evaluate the gains. To get even slightly better composition in some regimes (and also more flexible), use the results of [Kairouz et al. (2015)](http://proceedings.mlr.press/v37/kairouz15.pdf), for instance Corollary 4.1 therein."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
